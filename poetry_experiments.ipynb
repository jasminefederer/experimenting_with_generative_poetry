{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data input file is an ndjson [newline delimited JSON format](http://ndjson.org/)\n",
    "# this means there's a json object on each line so it can recognise line breaks\n",
    "\n",
    "# read the file and create a list `all_lines` that contains all of these json objects\n",
    "\n",
    "import json\n",
    "\n",
    "all_lines = []\n",
    "for line in open(\"blankmeanderings.ndjson\"):\n",
    "    all_lines.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_1': 'dense shell of oblivion. '},\n",
       " {'column_1': 'and the desire to please cling on to what was known, to become something that can no '},\n",
       " {'column_1': 'bromine exists; and hydrogen, hydrogen'},\n",
       " {'column_1': 'and she waits for their laughter to warm her'},\n",
       " {'column_1': 'longer be made sense of, and to end up just always searching for something to attempt to '},\n",
       " {'column_1': 'he pulls my knickers down. they fall between my ankles.'},\n",
       " {'column_1': 'we have flower particles inside our body now working as inner amulets.'},\n",
       " {'column_1': 'growths, shed sin displaced by other decayed life. ancestral matter - face mask?'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see what those lines look like, let's pick a handful at random\n",
    "\n",
    "import random\n",
    "\n",
    "# each object has a key 'column_1' that contains the text of the line of poetry\n",
    "\n",
    "random.sample(all_lines, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_1': 'we rise from our slumber ... yet what lies yonder? '},\n",
       " {'column_1': 'wildflowers caressing my legs being no less material than the desire to prove it all '},\n",
       " {'column_1': 'their broken bone arms and torn up flesh'},\n",
       " {'column_1': 'and the longing will overcome her'},\n",
       " {'column_1': \"again by the ocean's dark belly. this is a different kind of 'hydrological cycle'.\"},\n",
       " {'column_1': 'pond life, sea monkey, primordial soup, amphibious egg, the moist soil that '},\n",
       " {'column_1': 'the soil beneath my viscera breeds glyphs of ancient symbiotic harmonies, casting a copious '},\n",
       " {'column_1': 'mate. and you pretend that the days of the excruciating sweet fruit have passed, because '}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_lines, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concordances and counts\n",
    "\n",
    "the corpus could be useful for collecting, counting and comparing lines of poetry with certain characteristics (dependant on your input file data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's our first experiment: find every line of poetry in the corpus with the word \"love\"\n",
    "# we do this using a regular expression that finds the string 'love' between two word boundaries, without respect to case:\n",
    "\n",
    "import re\n",
    "love_lines = [line['column_1'] for line in all_lines if re.search(r'\\blove\\b', line['column_1'], re.I)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she scratches her love against the slime of the wall',\n",
       " 'she scratches her love against the slime of the wall',\n",
       " 'it is love that brings the sun out',\n",
       " 'it is rather the mesmerizing complications of sentimentality, artificial jealousies, words that inebriate and deceive, the rhetoric of parting and eternal fidelities, literary nostalgiaâ€”all the histrionics of love.',\n",
       " \"you love what i've done with the place? fossilised passages in a fine sausage casing gravel \",\n",
       " 'to long for a perennial love']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see what we have, we'll take a random sample:\n",
    "# (the number of lines you sample can be higher or lower depending on how many expressions of 'love' your file input contains)\n",
    "\n",
    "random.sample(love_lines, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                  she scratches her love against the slime of the wall\n",
      "                                                                                                                                                                                                  she scratches her love against the slime of the wall\n",
      "                                                                                                                                                                                                              it is love that brings the sun out\n",
      "                                                                                                                                                                                                                you love what i've done with the place? fossilised passages in sedimental ruins \n"
     ]
    }
   ],
   "source": [
    "# as a cut-up method poem, that's not bad all on its own... but let's do a little bit of Digital Humanities and make an aligned concordance of these lines, with the lines sorted alphabetically by the word following \"love,\" using a bit of regular expression trickery:\n",
    "# this will only work if you have enough \n",
    "\n",
    "longest = max([len(x) for x in love_lines]) # find the length of the longest line\n",
    "center = longest - len(\"love\") # and use it to create a \"center\" offset that will work for all lines\n",
    "\n",
    "sorted_love_lines = sorted(\n",
    "    [line for line in love_lines if re.search(r\"\\blove\\b\\s\\w\", line)], # only lines with word following\n",
    "    key=lambda line: line[re.search(r\"\\blove\\b\\s\", line).end():]) # sort on the substring following the match\n",
    "\n",
    "for line in sorted_love_lines: # add [interger:interger] if you wish to sample only a specific slice of your line selection\n",
    "    offset = center - re.search(r'\\blove\\b', line, re.I).start()\n",
    "    print((\" \"*offset)+line) # left-pad the string with spaces to align on \"love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as another experiment, let's find all of the words that occur between either \"the\" or \"a\" and the word \"love.\" English being the way it is, these words are pretty much guaranteed to be adjectives, so this is an ersatz but effective way of getting a (non-exhaustive) list of adjectives that are used to describe love in the corpus.\n",
    "\n",
    "found_adj = []\n",
    "for line in love_lines:\n",
    "    matches = re.findall(r\"(the|a)\\s(\\b\\w+\\b)\\s(\\blove\\b)\", line, re.I)\n",
    "    for match in matches: \n",
    "        found_adj.append(match[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perennial']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some adjectives at random:\n",
    "\n",
    "# there was only 1 adjective to describe love in my input, being 'perennial' otherwise make number higher to perform next steps\n",
    "\n",
    "\n",
    "random.sample(found_adj, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the `Counter` object, we can easily count these up and find the (12) most common adjectives (used in the type of noun phrase we've identified) used to describe love:\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(found_adj).most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rhymes\n",
    "\n",
    "stretches of language identified as poetry characteristically exhibit some variety of rhyming\n",
    "\n",
    "let's set ourselves a task of finding random rhyming lines in the corpus\n",
    "\n",
    "to do this, we need to know how words are pronounced... the way that words are spelled in English doesn't really tell us anything helpful about how the word is pronounced, so we need some alternate method to get that information\n",
    "\n",
    "the [CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) is one such method: it's a big database of phonetic transcriptions for many thousands of English words\n",
    "\n",
    "there is a Python library called [pronouncing] (https://pypi.org/project/pronouncing/) made by the amazing Allison Parrish (the person who inspired me to experiment with digital poetry) to make it very easy to work with the CMU Pronouncing Dictionary in Python\n",
    "\n",
    "you can install it in with pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pronouncing in c:\\users\\jasmi\\documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in c:\\users\\jasmi\\documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\venv\\lib\\site-packages (from pronouncing) (1.0.13)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in c:\\users\\jasmi\\documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\venv\\lib\\site-packages (from cmudict>=0.4.0->pronouncing) (5.2.0)\n",
      "Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in c:\\users\\jasmi\\documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\venv\\lib\\site-packages (from cmudict>=0.4.0->pronouncing) (5.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jasmi\\documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\venv\\lib\\site-packages (from importlib-metadata<6.0.0,>=5.1.0->cmudict>=0.4.0->pronouncing) (3.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pronouncing library like so\n",
    "\n",
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll consider two lines to rhyme with each other if the last words in the lines rhyme...\n",
    "# to test this out, we'll pick a source word, say, \"kiss,\" and find all of the words that rhyme with it:\n",
    "\n",
    "source_word = \"kiss\"\n",
    "source_word_rhymes = pronouncing.rhymes(source_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abyss',\n",
       " 'alusuisse',\n",
       " 'amiss',\n",
       " 'bis',\n",
       " 'biss',\n",
       " 'bliss',\n",
       " \"bliss'\",\n",
       " 'brys',\n",
       " 'buice',\n",
       " 'chris',\n",
       " \"chris'\",\n",
       " 'chriss',\n",
       " 'cris',\n",
       " 'criss',\n",
       " 'dis',\n",
       " 'dismiss',\n",
       " 'diss',\n",
       " 'fariss',\n",
       " 'fis',\n",
       " 'fiss',\n",
       " 'flis',\n",
       " 'fliss',\n",
       " 'furniss',\n",
       " 'hiss',\n",
       " 'kis',\n",
       " 'kniss',\n",
       " 'kris',\n",
       " 'kriss',\n",
       " 'lis',\n",
       " 'liss',\n",
       " 'mis',\n",
       " 'miss',\n",
       " 'phariss',\n",
       " 'piss',\n",
       " 'pris',\n",
       " 'reminisce',\n",
       " 'remiss',\n",
       " 'resists',\n",
       " 'resists',\n",
       " 'riss',\n",
       " 'risse',\n",
       " 'rys',\n",
       " 'sis',\n",
       " 'stys',\n",
       " 'suess',\n",
       " 'suisse',\n",
       " 'swiss',\n",
       " 'this',\n",
       " \"this'\",\n",
       " 'twiss',\n",
       " 'vis',\n",
       " 'wis',\n",
       " 'wiss',\n",
       " 'wyss']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_word_rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abyss\n",
      "abyss\n"
     ]
    }
   ],
   "source": [
    "# and then look through the lines of poetry in the corpus for lines that end with any of these rhyming words:\n",
    "\n",
    "for line in all_lines:\n",
    "    text = line['column_1']\n",
    "    match = re.search(r'(\\b\\w+\\b)\\W*$', text)\n",
    "    if match:\n",
    "        last_word = match.group()\n",
    "        if last_word in source_word_rhymes:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K IH1 S'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# depending on the size of your data input, looking through all the lines of poetry to find rhyming lines one-by-one might be pretty slow\n",
    "# another approach is to use the `phones_for_word()` and `rhyming_part()` functions in the `pronouncing` library to pre-build a data structure with all of the lines in the corpus grouped with their rhymes\n",
    "# the `phones_for_word()` function gives you the \"phones\" (sounds) of how a word is pronounced\n",
    "\n",
    "phones = pronouncing.phones_for_word(source_word)[0] # words may have multiple pronunciations, so this returns a list\n",
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IH1 S'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the `rhyming_part()` function gives you just the portion of a string of phones that another word must share in order for them to be considered \"rhyming\"\n",
    "\n",
    "pronouncing.rhyming_part(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we build the data structure proposed above: a dictionary that maps rhyming parts to a dictionary that maps words with that rhyming part to the lines of poetry that they're found at the end of\n",
    "\n",
    "from collections import defaultdict\n",
    "by_rhyming_part = defaultdict(lambda: defaultdict(list))\n",
    "for line in all_lines:\n",
    "    text = line['column_1']\n",
    "    if not(32 < len(text) < 48): # only use lines of uniform lengths\n",
    "        continue\n",
    "    match = re.search(r'(\\b\\w+\\b)\\W*$', text)\n",
    "    if match:\n",
    "        last_word = match.group()\n",
    "        pronunciations = pronouncing.phones_for_word(last_word)\n",
    "        if len(pronunciations) > 0:\n",
    "            rhyming_part = pronouncing.rhyming_part(pronunciations[0])\n",
    "            # group by rhyming phones (for rhymes) and words (to avoid duplicate words)\n",
    "            by_rhyming_part[rhyming_part][last_word.lower()].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IY1 S IH0 Z',\n",
       " defaultdict(list,\n",
       "             {'creases': ['holding vulnerability in its creases',\n",
       "               'holding vulnerability in its creases']}))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a random key/value pair from this dictionary, so you can see its structure:\n",
    "\n",
    "random_rhyming_part = random.choice(list(by_rhyming_part.keys()))\n",
    "random_rhyming_part, by_rhyming_part[random_rhyming_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# many rhyming parts are found in multiple lines, but only with one unique word\n",
    "# while it's true that identical words \"rhyme,\" it's a little disingenuous to claim that we've made a computer program that finds rhyming lines of poetry if it's mostly just finding lines that end in the same word\n",
    "# so we'll just find the groups from the `by_rhyming_part` dictionary that have at least two different line-ending words:\n",
    "\n",
    "rhyme_groups = [group for group in by_rhyming_part.values() if len(group) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jasmi\\Documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\markov-experiments.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/markov-experiments.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# now, find (7) rhyming couplets by selecting a random rhyming group, sampling two keys (words) from that group, and printing a random line from both groups:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/markov-experiments.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m7\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/markov-experiments.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     group \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mchoice(rhyme_groups)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/markov-experiments.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     words \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(\u001b[39mlist\u001b[39m(group\u001b[39m.\u001b[39mkeys()), \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/markov-experiments.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(random\u001b[39m.\u001b[39mchoice(group[words[\u001b[39m0\u001b[39m]]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:378\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[39m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m \u001b[39mreturn\u001b[39;00m seq[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_randbelow(\u001b[39mlen\u001b[39;49m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# now, find (7) rhyming couplets by selecting a random rhyming group, sampling (2) keys (words) from that group, and printing a random line from both groups:\n",
    "\n",
    "for i in range(7):\n",
    "    group = random.choice(rhyme_groups)\n",
    "    words = random.sample(list(group.keys()), 2)\n",
    "    print(random.choice(group[words[0]]))\n",
    "    print(random.choice(group[words[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markov chain text generation\n",
    "\n",
    "markov chain text generation uses statistical information about word co-occurrence to build a model that allows you to generate text that looks similar to your source text\n",
    "\n",
    "[Markovify](https://github.com/jsvine/markovify) is a great library for Python that makes it easy to build and generate from Markov chain models\n",
    "\n",
    "install it by pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markovify\n",
      "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting unidecode (from markovify)\n",
      "  Using cached Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "Building wheels for collected packages: markovify\n",
      "  Building wheel for markovify (setup.py): started\n",
      "  Building wheel for markovify (setup.py): finished with status 'done'\n",
      "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18649 sha256=e9dd29291a3abee5c1f87b1cd266713fc52bc803cb855d6a5791c9b8afa12797\n",
      "  Stored in directory: c:\\users\\jasmi\\appdata\\local\\pip\\cache\\wheels\\ca\\8c\\c5\\41413e24c484f883a100c63ca7b3b0362b7c6f6eb6d7c9cc7f\n",
      "Successfully built markovify\n",
      "Installing collected packages: unidecode, markovify\n",
      "Successfully installed markovify-0.9.4 unidecode-1.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our goal is to use a Markov chain to generate new lines of poetry from the corpus\n",
    "# markovify requires you to pass in your source text as a string, so first off we'll create a big string with a sample of the corpus, separated by newlines:\n",
    "# (you can change the number as needed; I had to keep it low at 300 as I did not have anymore lines to work with)\n",
    "\n",
    "big_poem = \"\\n\".join([line['column_1'] for line in random.sample(all_lines, 300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "model = markovify.NewlineText(big_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rituals stir within the metaverse serves as the womb,\n",
      "mate. and you pretend that the days of the cyber in an unending lore.\n",
      "she scratches her love against the slime of the metaverse womb, my life is a mere drop in the mind, and you find yourself moving against\n",
      "the face of a more general aqueous facilitative capacity: pond life, sea monkey, primordial soup, amphibious egg, the moist soil that\n",
      "patient, the sun refused to rise, and the ampersand, a languid swamp,\n",
      "fur, and his head is full of light\n",
      "citrus trees; cicadas exist; chicory, chromium,\n",
      "i traverse the metaverse shapeshifts, bound solely by the sun\n",
      "human bodies ingest reservoir bodies, while reservoir bodies are consumed by whale bodies - which then sink to the natural state, before this supernatural thing clouded\n",
      "with one gulp then another, their bodies fill the length of her limbs like a mist-clung spider's web or the caress of an\n",
      "here, in this fugue of flux, imbued with the fruit and\n",
      "the wyrm will dance to the beat of the inevitable intricacy of intersections, a beast born from\n",
      "None\n",
      "erasure poetry of existence where each convolution births the next, a posthuman gestation persists, echoic throbs\n"
     ]
    }
   ],
   "source": [
    "# and then generate some lines:\n",
    "\n",
    "for i in range(14):\n",
    "    print(model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromine exists; and blackberries, blackberries;'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is okay but the lines don't make a lot of sense, and are sometimes too long\n",
    "# you can constrain the length using Markovify's `.make_short_sentence()` method:\n",
    "\n",
    "model.make_short_sentence(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "with it in the back of her limbs\n",
      "unseen other than in the freedom of the\n",
      "rock chalk and the eternal dance\n",
      "bracken exists; and hydrogen, hydrogen.\n",
      "\n",
      "～ ❀ ～\n",
      "\n",
      "patient, the sun out\n",
      "patient, the sun out\n",
      "a pool of data this.\n",
      "\n",
      "～ ❀ ～\n",
      "\n",
      "None\n",
      "i sat on something that can no\n",
      "exist, and the desire to prove it all.\n",
      "\n",
      "～ ❀ ～\n",
      "\n",
      "the face of a mouth\n",
      "and the eternal dance\n",
      "and only the stars that\n",
      "fur, and his mind is made of matted.\n",
      "\n",
      "～ ❀ ～\n",
      "\n",
      "shiver in the freedom of the moon\n",
      "None\n",
      "erasure poetry of the wall\n",
      "porous flesh of the caves entrance\n",
      "in the caves entrance.\n",
      "\n",
      "～ ❀ ～\n",
      "\n",
      "bracken exists; and hydrogen, hydrogen\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jasmi\\Documents\\research and development\\poetry\\aparrish\\gutenberg-poetry-corpus-master\\gutenberg-poetry-corpus-master\\quick-experiments_edited.ipynb Cell 54\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/quick-experiments_edited.ipynb#Y104sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mmake_short_sentence(\u001b[39m40\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/quick-experiments_edited.ipynb#Y104sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# ensure last line has a period at the end, for closure\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/quick-experiments_edited.ipynb#Y104sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(re\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m(\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mw)[^\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mw.]?$\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m1.\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m.\u001b[39;49mmake_short_sentence(\u001b[39m40\u001b[39;49m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/quick-experiments_edited.ipynb#Y104sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jasmi/Documents/research%20and%20development/poetry/aparrish/gutenberg-poetry-corpus-master/gutenberg-poetry-corpus-master/quick-experiments_edited.ipynb#Y104sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m～ ❀ ～\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\re.py:209\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    203\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# I find that Markov-generated text is best when you keep it short and force juxtapositions, otherwise the reader's attention will wander\n",
    "# lets generate a series of short, haiku-esque poems of two to five Markov-generated lines, and ensure that the last line of each poem ends with a period:\n",
    "\n",
    "for i in range(6):\n",
    "    print()\n",
    "    for i in range(random.randrange(1, 5)):\n",
    "        print(model.make_short_sentence(40))\n",
    "    # ensure last line has a period at the end, for closure\n",
    "    print(re.sub(r\"(\\w)[^\\w.]?$\", r\"\\1.\", model.make_short_sentence(40)))\n",
    "    print()\n",
    "    print(\"～ ❀ ～\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
